import os
from flask import Flask, request, jsonify, Response
from flask_cors import CORS
import json

from allin_llmflow.assets.asset_factory import AssetFactory
from allin_llmflow.assets.model_services import ChatModelService
from allin_llmflow.dataclasses.chat_message import ChatMessage

# åˆå§‹åŒ– Flask åº”ç”¨
app = Flask(__name__)
CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚

# ä½ çš„ALLIN Token - è¯·æ›¿æ¢ä¸ºå®é™…çš„ Token
os.environ["ALLIN_ASSET_STORAGE_TOKEN"] = "AIT5533445c69b99fa510ae9e0512b7b546"

# åŠ è½½èŠå¤©æ¨¡å‹æœåŠ¡ - è¯·æ›¿æ¢ä¸ºå®é™…çš„ service ID
try:
    chat_model_service: ChatModelService = AssetFactory.load_from_allin("<insert-your-directllm-service-here>")
    print("âœ… AI æ¨¡å‹æœåŠ¡åŠ è½½æˆåŠŸ")
except Exception as e:
    print(f"âŒ AI æ¨¡å‹æœåŠ¡åŠ è½½å¤±è´¥: {e}")
    chat_model_service = None


@app.route('/api/chat', methods=['POST'])
def chat():
    """å¤„ç†èŠå¤©è¯·æ±‚"""
    try:
        if chat_model_service is None:
            return jsonify({
                "error": "AI æ¨¡å‹æœåŠ¡æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥é…ç½®"
            }), 500

        data = request.json
        user_message = data.get('message', '')
        stream = data.get('stream', False)
        model = data.get('model', 'qwen2.5-72b-instruct')
        
        if not user_message:
            return jsonify({"error": "æ¶ˆæ¯ä¸èƒ½ä¸ºç©º"}), 400

        # æ„å»ºæ¶ˆæ¯å†å²
        messages = []
        if 'history' in data and isinstance(data['history'], list):
            for msg in data['history']:
                if msg.get('role') == 'user':
                    messages.append(ChatMessage.from_user(msg.get('content', '')))
                elif msg.get('role') == 'assistant':
                    messages.append(ChatMessage.from_assistant(msg.get('content', '')))
        
        # æ·»åŠ å½“å‰æ¶ˆæ¯
        messages.append(ChatMessage.from_user(user_message))

        # æµå¼å“åº”
        if stream:
            def generate():
                collected_chunks = []
                
                def on_chunk(chunk):
                    collected_chunks.append(chunk)
                    # å‘é€ SSE æ ¼å¼çš„æ•°æ®
                    yield f"data: {json.dumps({'chunk': chunk, 'done': False})}\n\n"
                
                try:
                    # è°ƒç”¨ AI æ¨¡å‹ï¼ˆæµå¼ï¼‰
                    replies = chat_model_service.infer(
                        messages=messages,
                        model=model,
                        timeout=60,
                        stream=True,
                        streaming_callbacks=[on_chunk]
                    )
                    
                    # å‘é€å®Œæˆä¿¡å·
                    full_response = ''.join(collected_chunks)
                    yield f"data: {json.dumps({'chunk': '', 'done': True, 'full_response': full_response})}\n\n"
                    
                except Exception as e:
                    error_msg = f"AI è°ƒç”¨é”™è¯¯: {str(e)}"
                    yield f"data: {json.dumps({'error': error_msg, 'done': True})}\n\n"
            
            return Response(generate(), mimetype='text/event-stream')
        
        # éæµå¼å“åº”
        else:
            replies = chat_model_service.infer(
                messages=messages,
                model=model,
                timeout=60
            )
            
            return jsonify({
                "response": replies[0].content if replies else "æ— å“åº”",
                "model": model
            })

    except Exception as e:
        return jsonify({"error": f"æœåŠ¡å™¨é”™è¯¯: {str(e)}"}), 500


@app.route('/api/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return jsonify({
        "status": "ok",
        "service": "AI Chat Service",
        "port": 5566,
        "model_loaded": chat_model_service is not None
    })


@app.route('/api/models', methods=['GET'])
def get_models():
    """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    return jsonify({
        "models": [
            {"id": "qwen2.5-72b-instruct", "name": "Qwen 2.5 72B"},
            {"id": "qwen2.5-32b-instruct", "name": "Qwen 2.5 32B"},
            {"id": "qwen2.5-14b-instruct", "name": "Qwen 2.5 14B"}
        ]
    })


if __name__ == '__main__':
    print("ğŸš€ å¯åŠ¨ AI èŠå¤©æœåŠ¡...")
    print("ğŸ“¡ ç›‘å¬ç«¯å£: 5566")
    print("ğŸ”— å¥åº·æ£€æŸ¥: http://localhost:5566/api/health")
    print("ğŸ’¬ èŠå¤©æ¥å£: http://localhost:5566/api/chat")
    
    app.run(host='0.0.0.0', port=5566, debug=True)